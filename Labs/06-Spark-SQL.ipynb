{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd3e48d9-3da0-45df-90a6-bf96d264a1ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Spark SQL**\n",
    "\n",
    "### SQL in Spark: Overview and Usage\n",
    "\n",
    "Spark SQL is a module in Apache Spark that provides a structured data processing interface using SQL-like queries. It bridges the gap between the relational and procedural paradigms, allowing data analysts and developers to interact with data using SQL while leveraging Spark's scalability and performance.\n",
    "\n",
    "**Key Features of Spark SQL:**\n",
    "- **Unified Data Access**: Access data from various sources like JSON, Parquet, Avro, Hive, and JDBC.\n",
    "- **Schema-Based Processing**: Enables schema definition and enforcement for structured data.\n",
    "- **Integration with DataFrames**: Allows seamless transitions between SQL queries and DataFrame APIs.\n",
    "- **Optimized Query Execution**: Uses the Catalyst Optimizer for efficient query planning.\n",
    "\n",
    "*Example 1: Running SQL queries on a DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20dbdbc8-07f9-439e-b20a-b45997668594",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "| DEST_COUNTRY_NAME|total_flights|\n",
      "+------------------+-------------+\n",
      "|     United States|     411337.0|\n",
      "|            Canada|       8399.0|\n",
      "|            Mexico|       7140.0|\n",
      "|    United Kingdom|       2025.0|\n",
      "|             Japan|       1548.0|\n",
      "|           Germany|       1468.0|\n",
      "|Dominican Republic|       1353.0|\n",
      "|       South Korea|       1048.0|\n",
      "|       The Bahamas|        955.0|\n",
      "|            France|        935.0|\n",
      "+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from JSON\n",
    "flight_data_json = \"dbfs:/mnt/data/data/flight-data/json/2015-summary.json\"\n",
    "df = spark.read.format(\"json\").load(flight_data_json)\n",
    "\n",
    "# Register DataFrame as a SQL table\n",
    "df.createOrReplaceTempView(\"flight_data\")\n",
    "\n",
    "# Query using Spark SQL\n",
    "query = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, SUM(count) AS total_flights \n",
    "FROM flight_data \n",
    "GROUP BY DEST_COUNTRY_NAME \n",
    "ORDER BY total_flights DESC \n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "sql_result = spark.sql(query)\n",
    "sql_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25624544-cc39-40d9-b386-6feaea5db59c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Creating and Managing Tables with Spark SQL\n",
    "\n",
    "Spark SQL allows users to create and manage tables, supporting both temporary and permanent tables.\n",
    "\n",
    "**1. Temporary Views:**\n",
    "Temporary views exist only within the Spark session and are not persistent.\n",
    "\n",
    "*Example 2: Creating and querying a temporary view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd92eaae-ef33-44c1-8600-84d37f1c4f7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|ORIGIN_COUNTRY_NAME|num_flights|\n",
      "+-------------------+-----------+\n",
      "|      United States|        132|\n",
      "+-------------------+-----------+\n",
      "\n",
      "+-------------------+----------------+------------------+\n",
      "|ORIGIN_COUNTRY_NAME|total_passengers|       avg_flights|\n",
      "+-------------------+----------------+------------------+\n",
      "|      United States|        411966.0|3120.9545454545455|\n",
      "|             Canada|          8483.0|            8483.0|\n",
      "|             Mexico|          7187.0|            7187.0|\n",
      "|     United Kingdom|          1970.0|            1970.0|\n",
      "|              Japan|          1496.0|            1496.0|\n",
      "| Dominican Republic|          1420.0|            1420.0|\n",
      "|            Germany|          1336.0|            1336.0|\n",
      "|        The Bahamas|           986.0|             986.0|\n",
      "|             France|           952.0|             952.0|\n",
      "|              China|           920.0|             920.0|\n",
      "+-------------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a temporary view\n",
    "df.createOrReplaceTempView(\"temp_flights\")\n",
    "\n",
    "# Querying the temporary view\n",
    "query = \"\"\"\n",
    "SELECT ORIGIN_COUNTRY_NAME, COUNT(*) AS num_flights\n",
    "FROM temp_flights\n",
    "GROUP BY ORIGIN_COUNTRY_NAME\n",
    "HAVING num_flights > 10\n",
    "ORDER BY num_flights DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "spark.sql(query).show()\n",
    "\n",
    "# More complex query with multiple aggregations\n",
    "query_advanced = \"\"\"\n",
    "SELECT ORIGIN_COUNTRY_NAME, SUM(count) AS total_passengers, AVG(count) AS avg_flights\n",
    "FROM temp_flights\n",
    "GROUP BY ORIGIN_COUNTRY_NAME\n",
    "ORDER BY total_passengers DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "spark.sql(query_advanced).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4253f97-d3a9-4044-b1f1-b9b4fb92060c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2. Global Temporary Views:**\n",
    "Global temporary views are accessible across multiple sessions using the `global_temp` database.\n",
    "\n",
    "*Example 3: Creating and querying a global temporary view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "757f82aa-3397-4d21-ac1e-d4d56d3c5e6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+\n",
      "| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+------------------+-------------------+------+\n",
      "|        Costa Rica|      United States|   588|\n",
      "|     United States|        Netherlands|   660|\n",
      "|       The Bahamas|      United States|   955|\n",
      "|       El Salvador|      United States|   561|\n",
      "|            Mexico|      United States|  7140|\n",
      "|     United States|         Costa Rica|   608|\n",
      "|          Colombia|      United States|   873|\n",
      "|     United States|            Jamaica|   712|\n",
      "|            Panama|      United States|   510|\n",
      "|     United States|        The Bahamas|   986|\n",
      "|     United States|              China|   920|\n",
      "|     United States| Dominican Republic|  1420|\n",
      "|     United States|      United States|370002|\n",
      "|           Germany|      United States|  1468|\n",
      "|     United States|        South Korea|   827|\n",
      "|     United States|        El Salvador|   508|\n",
      "|            Canada|      United States|  8399|\n",
      "|           Jamaica|      United States|   666|\n",
      "|Dominican Republic|      United States|  1353|\n",
      "|             Japan|      United States|  1548|\n",
      "+------------------+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a global temporary view\n",
    "df.createOrReplaceGlobalTempView(\"global_flights\")\n",
    "\n",
    "# Query the global view\n",
    "query = \"SELECT * FROM global_temp.global_flights WHERE count > 500\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7131642c-8754-4dc9-a6dc-1ac9661e1eeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3. Managed Tables:**\n",
    "Managed tables are stored in Spark's warehouse directory and managed by Spark.\n",
    "\n",
    "*Example 4: Creating a managed table and inserting data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f99c11-f34f-4bfa-921a-de3d3555988b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania| NULL|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS managed_table (DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\")\n",
    "spark.sql(\"INSERT INTO managed_table SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, TRY_CAST(count AS LONG) AS count FROM temp_flights\")\n",
    "spark.sql(\"SELECT * FROM managed_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a55390d-1324-45b0-b1f8-b68c8d30e87f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Performance Optimization with Catalyst Optimizer\n",
    "\n",
    "The Catalyst Optimizer is a key component of Spark SQL, designed to enhance query performance through logical and physical plan optimization.\n",
    "\n",
    "**Key Techniques:**\n",
    "- **Predicate Pushdown:** Filters are applied early to reduce data scanning.\n",
    "- **Column Pruning:** Reads only required columns from the data source.\n",
    "- **Join Optimization:** Reorders joins for optimal execution.\n",
    "- **Query Caching:** Uses in-memory storage for frequently accessed data.\n",
    "\n",
    "*Example 6: Using query caching for performance optimization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc0a4e0-d5cc-401a-902c-903e2d3da317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|   DEST_COUNTRY_NAME|total_flights|\n",
      "+--------------------+-------------+\n",
      "|            Anguilla|         41.0|\n",
      "|              Russia|        176.0|\n",
      "|            Paraguay|         60.0|\n",
      "|             Senegal|         40.0|\n",
      "|              Sweden|        118.0|\n",
      "|            Kiribati|         26.0|\n",
      "|              Guyana|         64.0|\n",
      "|         Philippines|        134.0|\n",
      "|            Djibouti|          1.0|\n",
      "|            Malaysia|          2.0|\n",
      "|           Singapore|          3.0|\n",
      "|                Fiji|         24.0|\n",
      "|              Turkey|        138.0|\n",
      "|                Iraq|          1.0|\n",
      "|             Germany|       1468.0|\n",
      "|              Jordan|         44.0|\n",
      "|               Palau|         30.0|\n",
      "|Turks and Caicos ...|        230.0|\n",
      "|              France|        935.0|\n",
      "|              Greece|         30.0|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cache query result\n",
    "cached_result = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, SUM(count) AS total_flights\n",
    "FROM flight_data\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")\n",
    "cached_result.cache()\n",
    "cached_result.count()\n",
    "cached_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a26e81ad-c979-4f58-816d-e3aaf2fc5a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Using Databricks SQL for Queries and Visualization\n",
    "\n",
    "Databricks SQL provides a user-friendly interface for running SQL queries and creating visualizations.\n",
    "\n",
    "**Steps to Use Databricks SQL:**\n",
    "1. Navigate to the SQL editor in Databricks.\n",
    "2. Select or create a SQL warehouse.\n",
    "3. Write and execute SQL queries.\n",
    "4. Create dashboards and visualizations.\n",
    "\n",
    "*Example 7: Running a SQL query in Databricks SQL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea8824e-b5c0-4534-8319-5cd165a83495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "| DEST_COUNTRY_NAME|total_flights|\n",
      "+------------------+-------------+\n",
      "|     United States|       411337|\n",
      "|            Canada|         8399|\n",
      "|            Mexico|         7140|\n",
      "|    United Kingdom|         2025|\n",
      "|             Japan|         1548|\n",
      "|           Germany|         1468|\n",
      "|Dominican Republic|         1353|\n",
      "|       South Korea|         1048|\n",
      "|       The Bahamas|          955|\n",
      "|            France|          935|\n",
      "+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, SUM(count) AS total_flights\n",
    "FROM managed_table\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY total_flights DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2f52d21-ceb4-4e19-ad43-093486b8d06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M4-Spark-SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
